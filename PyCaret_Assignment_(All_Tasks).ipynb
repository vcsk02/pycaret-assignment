{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"--- [STEP 1] Starting Python 3.11 setup (This takes ~1 minute) ---\")\n",
        "\n",
        "# 1. Install Python 3.11 and its development libraries\n",
        "!sudo apt-get update -y > /dev/null\n",
        "!sudo apt-get install python3.11 python3.11-dev -y > /dev/null\n",
        "\n",
        "# 2. Set Python 3.11 as the default 'python3'\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 > /dev/null\n",
        "\n",
        "# 3. Install pip for Python 3.11\n",
        "!sudo apt-get install python3.11-distutils -y > /dev/null\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.11 > /dev/null\n",
        "\n",
        "# 4. Install PyCaret 3.3.2 (the latest stable version) using the new Python 3.11\n",
        "# We also install openpyxl for Task D\n",
        "print(\"Installing PyCaret 3.3.2, mlflow, and openpyxl... (This may take a moment)\")\n",
        "# FIX: Added 'mlflow' to the install list to prevent ImportError\n",
        "!python3.11 -m pip install pycaret[full]==3.3.2 openpyxl mlflow > /dev/null\n",
        "\n",
        "print(\"--- Python 3.11 setup complete. ---\")\n",
        "!python3.11 --version\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"  >>>>> IMPORTANT: GO TO 'Runtime' -> 'Restart Session' NOW <<<<<  \")\n",
        "print(\"=\"*70 + \"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [STEP 1] Starting Python 3.11 setup (This takes ~1 minute) ---\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Installing PyCaret 3.3.2, mlflow, and openpyxl... (This may take a moment)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.6 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
            "plotnine 0.14.6 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m--- Python 3.11 setup complete. ---\n",
            "Python 3.11.14\n",
            "\n",
            "\n",
            "======================================================================\n",
            "  >>>>> IMPORTANT: GO TO 'Runtime' -> 'Restart Session' NOW <<<<<  \n",
            "======================================================================\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJInW7PKiRS",
        "outputId": "ebeb85d1-8f38-426b-cb68-134d39c33e85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. --- CRITICAL VALIDATION ---\n",
        "# Check the Python version *after* restart.\n",
        "import sys\n",
        "print(f\"--- Running Python Version: {sys.version_info.major}.{sys.version_info.minor} ---\")\n",
        "if not (sys.version_info.major == 3 and sys.version_info.minor == 11):\n",
        "    print(\"=\"*70)\n",
        "    print(\"  >>>>> ERROR: PYTHON 3.11 IS NOT ACTIVE. <<<<<  \")\n",
        "    print(\"  Please re-run STEP 1, then RESTART SESSION, then run this cell.\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"SUCCESS: Python 3.11 is active.\")\n",
        "\n",
        "    # 2. --- Import Libraries (FIXED) ---\n",
        "    import pandas as pd\n",
        "    from google.colab import drive\n",
        "    import os\n",
        "\n",
        "    # Import PyCaret modules with aliases\n",
        "    import pycaret.classification as pc\n",
        "    import pycaret.regression as pr\n",
        "    import pycaret.clustering as pclub\n",
        "    import pycaret.anomaly as pa\n",
        "    import pycaret.time_series as pts\n",
        "\n",
        "    print(\"PyCaret modules imported successfully.\")\n",
        "\n",
        "    # 3. --- Mount Google Drive & Load Data ---\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # This is the verified, correct path from our debugging\n",
        "    DATA_PATH = '/content/drive/MyDrive/fitness_dataset.csv'\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(DATA_PATH, parse_dates=['timestamp'])\n",
        "        print(\"Data loaded successfully:\")\n",
        "        print(data.head())\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not load data from Drive: {e}\")\n",
        "        print(f\"Please ensure '{DATA_PATH}' is the correct path.\")\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK A-1] Running Binary Classification\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK A-1] Running Binary Classification ---\")\n",
        "    data_binary = data.copy()\n",
        "    data_binary['high_calorie_burn'] = (data_binary['calories_burned'] > 300).astype(int)\n",
        "    data_binary = data_binary.drop(columns=['record_id', 'timestamp', 'user_id', 'calories_burned'])\n",
        "\n",
        "    clf1 = pc.setup(data=data_binary,\n",
        "                    target='high_calorie_burn',\n",
        "                    session_id=123,\n",
        "                    log_experiment=False,\n",
        "                    verbose=False)\n",
        "\n",
        "    best_binary = pc.compare_models(n_select=1, verbose=False)\n",
        "    tuned_binary = pc.tune_model(best_binary, optimize='AUC', verbose=False)\n",
        "\n",
        "    pc.plot_model(tuned_binary, plot='auc', save=True)\n",
        "    pc.plot_model(tuned_binary, plot='confusion_matrix', save=True)\n",
        "\n",
        "    try:\n",
        "        pc.plot_model(tuned_binary, plot='feature', save=True)\n",
        "    except TypeError:\n",
        "        print(\"Note: Feature Importance plot is not available for the selected model.\")\n",
        "\n",
        "    pc.save_model(tuned_binary, 'high_calorie_model')\n",
        "    print(\"--- Binary Classification Complete ---\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK A-2] Running Multiclass Classification\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK A-2] Running Multiclass Classification ---\")\n",
        "    data_multi = data.copy()\n",
        "    data_multi = data_multi.drop(columns=['record_id', 'timestamp', 'user_id'])\n",
        "\n",
        "    clf2 = pc.setup(data=data_multi,\n",
        "                    target='activity_type',\n",
        "                    session_id=124,\n",
        "                    log_experiment=False,\n",
        "                    verbose=False)\n",
        "\n",
        "    best_multi = pc.compare_models(n_select=1, verbose=False)\n",
        "    tuned_multi = pc.tune_model(best_multi, optimize='Accuracy', verbose=False)\n",
        "\n",
        "    pc.plot_model(tuned_multi, plot='confusion_matrix', save=True)\n",
        "\n",
        "    try:\n",
        "        pc.plot_model(tuned_multi, plot='feature', save=True)\n",
        "    except TypeError:\n",
        "        print(\"Note: Feature Importance plot is not available for the selected model.\")\n",
        "\n",
        "    pc.save_model(tuned_multi, 'activity_type_model')\n",
        "    print(\"--- Multiclass Classification Complete ---\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK A-3] Running Regression\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK A-3] Running Regression ---\")\n",
        "    data_reg = data.copy()\n",
        "    data_reg = data_reg.drop(columns=['record_id', 'timestamp', 'user_id'])\n",
        "\n",
        "    reg1 = pr.setup(data=data_reg,\n",
        "                    target='calories_burned',\n",
        "                    session_id=125,\n",
        "                    log_experiment=False,\n",
        "                    verbose=False)\n",
        "\n",
        "    best_reg = pr.compare_models(n_select=1, verbose=False)\n",
        "    tuned_reg = pr.tune_model(best_reg, optimize='MAE', verbose=False)\n",
        "\n",
        "    pr.plot_model(tuned_reg, plot='residuals', save=True)\n",
        "    pr.plot_model(tuned_reg, plot='error', save=True)\n",
        "\n",
        "    try:\n",
        "        pr.plot_model(tuned_reg, plot='feature', save=True)\n",
        "    except TypeError:\n",
        "        print(\"Note: Feature Importance plot is not available for the selected model.\")\n",
        "\n",
        "    pr.save_model(tuned_reg, 'calorie_regression_model')\n",
        "    print(\"--- Regression Complete ---\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK B] Running Clustering\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK B] Running Clustering ---\")\n",
        "    data_clu = data.copy()\n",
        "    data_clu = data_clu.drop(columns=['record_id', 'timestamp', 'user_id', 'activity_type'])\n",
        "\n",
        "    clu1 = pclub.setup(data=data_clu,\n",
        "                       session_id=126,\n",
        "                       log_experiment=False,\n",
        "                       verbose=False)\n",
        "\n",
        "    kmeans = pclub.create_model('kmeans', num_clusters=4, verbose=False)\n",
        "    pclub.assign_model(kmeans)\n",
        "\n",
        "    pclub.plot_model(kmeans, plot='cluster', save=True)\n",
        "    pclub.plot_model(kmeans, plot='elbow', save=True)\n",
        "    print(\"--- Clustering Complete ---\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK C] Running Anomaly Detection\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK C] Running Anomaly Detection ---\")\n",
        "    data_anom = data.copy()\n",
        "    data_anom = data_anom.drop(columns=['record_id', 'timestamp', 'user_id', 'activity_type'])\n",
        "\n",
        "    anom1 = pa.setup(data=data_anom,\n",
        "                     session_id=127,\n",
        "                     log_experiment=False,\n",
        "                     verbose=False)\n",
        "\n",
        "    iforest = pa.create_model('iforest', contamination=0.05, verbose=False)\n",
        "    pa.assign_model(iforest)\n",
        "\n",
        "    pa.plot_model(iforest, plot='umap', save=True)\n",
        "    print(\"--- Anomaly Detection Complete ---\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # [TASK E] Running Time Series Forecasting\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"\\n--- [TASK E] Running Time Series Forecasting ---\")\n",
        "\n",
        "    # --- Prepare Data for Time Series ---\n",
        "    ts_data = data.set_index('timestamp').resample('D').agg({\n",
        "        'steps': 'sum',\n",
        "        'duration_min': 'sum'\n",
        "    })\n",
        "    ts_data = ts_data.asfreq('D').fillna(0) # Fill missing days with 0\n",
        "    print(\"Time Series Data (Daily):\")\n",
        "    print(ts_data.head())\n",
        "\n",
        "    # --- Task E-1: Univariate without Exogenous Variables ---\n",
        "    print(\"\\n--- [TASK E-1] Running Univariate Forecast (No Exog) ---\")\n",
        "\n",
        "    setup_ts_no_exog = pts.setup(data=ts_data['steps'],\n",
        "                                 fh=7,  # Forecast 7 days ahead\n",
        "                                 session_id=129,\n",
        "                                 log_experiment=False,\n",
        "                                 verbose=False)\n",
        "\n",
        "    best_ts_no_exog = pts.compare_models(n_select=1, verbose=False)\n",
        "    pts.plot_model(best_ts_no_exog, plot='forecast', save=True)\n",
        "    print(\"--- Univariate Forecast Complete ---\")\n",
        "\n",
        "    # --- Task E-2: Univariate with Exogenous Variables ---\n",
        "    print(\"\\n--- [TASK E-2] Running Univariate Forecast (With Exog) ---\")\n",
        "\n",
        "    setup_ts_exog = pts.setup(data=ts_data,\n",
        "                              target='steps',\n",
        "                              fh=7,\n",
        "                              session_id=130,\n",
        "                              log_experiment=False,\n",
        "                              verbose=False)\n",
        "\n",
        "    best_ts_exog = pts.compare_models(n_select=1, verbose=False)\n",
        "    pts.plot_model(best_ts_exog, plot='forecast', save=True)\n",
        "    print(\"--- Univariate Forecast with Exogenous Complete ---\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Step 2 (Tasks A, B, C, E) Execution Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RN80q5auLuzy",
        "outputId": "e2670d77-6459-4421-f0fa-30ed6806b10c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Python Version: 3.11 ---\n",
            "SUCCESS: Python 3.11 is active.\n",
            "PyCaret modules imported successfully.\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Data loaded successfully:\n",
            "   record_id           timestamp user_id  age  gender      activity_type  \\\n",
            "0          1 2025-07-22 09:22:54    U026   67    Male            Cycling   \n",
            "1          2 2025-05-28 13:53:54    U039   16  Female  Strength Training   \n",
            "2          3 2025-08-07 01:36:54    U046   62  Female            Cycling   \n",
            "3          4 2025-07-17 01:56:54    U048   56  Female           Swimming   \n",
            "4          5 2025-08-11 03:22:54    U042   42   Other               Yoga   \n",
            "\n",
            "   duration_min  calories_burned  heart_rate_avg  steps  sleep_hours  \\\n",
            "0             7              322             175   3591          7.0   \n",
            "1            83              265             113  22312          5.7   \n",
            "2           118              508              98   5418          6.6   \n",
            "3            75              270             150  19809          7.9   \n",
            "4            76              308             141  12562          5.0   \n",
            "\n",
            "   weight_kg  \n",
            "0       84.3  \n",
            "1       79.6  \n",
            "2       88.3  \n",
            "3       69.0  \n",
            "4       61.6  \n",
            "\n",
            "--- [TASK A-1] Running Binary Classification ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n",
            "--- Binary Classification Complete ---\n",
            "\n",
            "--- [TASK A-2] Running Multiclass Classification ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Feature Importance plot is not available for the selected model.\n",
            "Transformation Pipeline and Model Successfully Saved\n",
            "--- Multiclass Classification Complete ---\n",
            "\n",
            "--- [TASK A-3] Running Regression ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n",
            "--- Regression Complete ---\n",
            "\n",
            "--- [TASK B] Running Clustering ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Clustering Complete ---\n",
            "\n",
            "--- [TASK C] Running Anomaly Detection ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Anomaly Detection Complete ---\n",
            "\n",
            "--- [TASK E] Running Time Series Forecasting ---\n",
            "Time Series Data (Daily):\n",
            "            steps  duration_min\n",
            "timestamp                      \n",
            "2025-04-24  11118           149\n",
            "2025-04-25  26158           197\n",
            "2025-04-26      0             0\n",
            "2025-04-27  37303           209\n",
            "2025-04-28  11255            23\n",
            "\n",
            "--- [TASK E-1] Running Univariate Forecast (No Exog) ---\n",
            "--- Univariate Forecast Complete ---\n",
            "\n",
            "--- [TASK E-2] Running Univariate Forecast (With Exog) ---\n",
            "--- Univariate Forecast with Exogenous Complete ---\n",
            "\n",
            "--- Step 2 (Tasks A, B, C, E) Execution Complete ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}